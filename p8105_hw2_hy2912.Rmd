---
title: "p8105_hw2_hy2912"
author: "Helen Yousaf"
date: "2024-09-26"
output: html_document
---

```{r setup}
library(tidyverse)
```

## Problem 1: NYC Transit 
#### Importing NYC Transit Data 

```{r, include = FALSE}
getwd()
```

```{r}
NYCTransit_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols (Route8="c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names()|>
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, exit_only, entry, vending, ada)|>
  mutate(entry = ifelse(entry=="YES", TRUE, FALSE))
```

#### Looking at data
```{r}
print(NYCTransit_df)
```
#### Unique stations
```{r}
NYCTransit_df|>
  select(station_name, line)|>
  distinct()
```
#### Filtering by ADA compliance 
```{r}
NYCTransit_df|>
  filter(ada==TRUE)|>
  select(station_name, line)|>
  distinct()
```
#### Station exntrances/exits wihtout vending 
```{r}
NYCTransit_df|>
  filter(vending == "NO")|>
  pull(entry)|>
  mean()
```
#### A train stations and ADA compliant 
```{r}
NYCTransit_df|>
  pivot_longer (
    route1:route11,
    names_to = "route_num",
    values_to = "route")|>
  filter (route == "A")|>
  select (station_name, line)|>
  distinct()
```
```{r}
NYCTransit_df|>
  pivot_longer (
    route1:route11,
    names_to = "route_num",
    values_to = "route")|>
  filter (route == "A", ada == TRUE)|>
  select (station_name, line)|>
  distinct()
```

#### Data Set Description 
This data set presents information related to NYC Transit data. More specifically, this CSV file contains information related to entrance and exit for each subway station in New York City. After data cleaning, the following variables were retained: line, station name, station latitude, station longitude, routes taken (1-11), entrance type, entry, vending, and ADA compliance. Other variables in the original data set that were not retained for the purpose of this HW. The raw data is organized in a 1868  x 32 table. The resulting data set has dimensions of 1868 rows x 20 columns.  There are 465 unique stations. Of these, 84 are ADA compliant. 50% of station entrances/exists without vending allow entrance. The entry variable was also changed to a logical variable. The proportion of station entrances/exits without vending allowed is 0.377. 17 stations serve the A train and are ADA compliant. This data is not tidy because the route number should be single variable in addition to the route. This can be done by transforming the variable from wide to long. 

## Problem 2: Mr.Trash Wheel 
#### Importing Mr. Trash Wheel Data_Excel and data cleaning
```{r}
library(readxl)
MrTrash_df = read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Mr. Trash Wheel", skip = 2, col_names = TRUE) %>%
select(-contains("notes")) %>%
mutate(Sports Balls = as.integer(round(Sports Balls)))
```
#### Add identifier for Mr. Trash Wheel
```{r}
MrTrash_df <- MrTrash_df %>%
  mutate(MrTrash_df = "Mr. Trash Wheel")
```

#### Read and clean Professor Trash Wheel data
```{r}
professor_trash_wheel <- read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Professor Trash Wheel", skip = 2, col_names = TRUE) %>%
select(-contains("notes")) %>%
```
#### Read and clean Gwynnda data
```{r}
gwynnda_df <- read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Gwynnda Trash Wheel", skip = 2, col_names = TRUE) %>%
  select(-contains("notes")) %>%
```

#### Combine datasets
```{r}
combined_data <- bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda)
```

#### Summary of the combined dataset
```{r}
num_observations <- nrow(combined_data)
total_weight_professor <- sum(professor_trash_wheel$Weight, na.rm = TRUE)
total_cigarette_butts_gwynnda_june_2022 <- gwynnda %>%
  filter(Month == "June" & Year == 2022) %>%
  summarise(Total_Cigarette_Butts = sum(Cigarette_Butts, na.rm = TRUE))
```

## Problem 3: The Great British Baking Show 
#### Importing The Great British Baking Show data 
```{r}
viewers_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/viewers.csv")
print(viewers_df)
bakers_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/bakers.csv")
print(bakers_df)
bakes_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/bakes.csv")
print(bakes_df)
results_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/results.csv" , skip = 2, col_names = TRUE)
print(results_df)
```
```{r}
rename(results_df, Episode = episode)
```

#### Clean and tidy bakers dataset
```{r}
bakers_df <- bakers_df %>%
janitor::clean_names() %>%
  filter(!is.na(baker_name))
```

#### Clean and tidy bakes dataset
```{r}
bakes_df <- bakes_df %>%
janitor::clean_names() %>%
  filter(!is.na(episode))
```

#### Clean and tidy results dataset
```{r}
results_df <- results_df %>%
janitor::clean_names() 
```

#### Check for completeness
```{r}
anti_bakers_bakes <- anti_join(bakers_df, bakes_df, by = "baker")
anti_bakes_results <- anti_join(bakes_df, results_df, by = "Episode")
```

#### Merge datasets
```{r}
final_dataset <- results_df %>%
  left_join(bakes_df, by = "episode") %>%
  left_join(bakers_df, by = "baker") %>%
  arrange(season, episode)
```

#### Exporting final dataset
```{r}
write_csv(final_dataset, "final_dataset.csv")
```

#### Creating a table for star bakers in Seasons 5 through 10
```{r}
star_bakers_table <- final_dataset %>%
  filter(season >= 5 & season <= 10) %>%
  select(season, episode, star_baker) %>%
  distinct() %>%
  arrange(season, episode)
```

#### Showing the first 10 rows of viewers dataset
```{r}
viewers_clean <- viewers_df %>%
janitor::clean_names()
```

```{r}
head(viewers_df_clean, 10)
```

#### Calculating average viewership in Season 1 and Season 5
```{r}
avg_viewership_season_1 <- viewers_df_clean %>%
  filter(season == 1) %>%
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
```

```{r}
avg_viewership_season_5 <- viewers_df_clean %>%
  filter(season == 5) %>%
  summarise(avg_viewership = mean(viewership, na.rm = TRUE))
```

