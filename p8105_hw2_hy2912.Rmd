---
title: "p8105_hw2_hy2912"
author: "Helen Yousaf"
date: "2024-09-26"
output: html_document
---

```{r setup}
library(tidyverse)
library(knitr)
library(tidyr)
```

## Problem 1: NYC Transit 
#### Importing NYC Transit Data 

```{r, include = FALSE}
getwd()
```

```{r}
NYCTransit_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols (Route8="c", Route9 = "c", Route10 = "c", Route11 = "c")) |>
  janitor::clean_names()|>
  select(line, station_name, station_latitude, station_longitude, route1:route11, entrance_type, exit_only, entry, vending, ada)|>
  mutate(entry = ifelse(entry=="YES", TRUE, FALSE))
```

#### Looking at data
```{r}
print(NYCTransit_df)
```
#### Unique stations
```{r}
NYCTransit_df|>
  select(station_name, line)|>
  distinct()
```
#### Filtering by ADA compliance 
```{r}
NYCTransit_df|>
  filter(ada==TRUE)|>
  select(station_name, line)|>
  distinct()
```
#### Station exntrances/exits wihtout vending 
```{r}
NYCTransit_df|>
  filter(vending == "NO")|>
  pull(entry)|>
  mean()
```
#### A train stations and ADA compliant 
```{r}
NYCTransit_df|>
  pivot_longer (
    route1:route11,
    names_to = "route_num",
    values_to = "route")|>
  filter (route == "A")|>
  select (station_name, line)|>
  distinct()
```
```{r}
NYCTransit_df|>
  pivot_longer (
    route1:route11,
    names_to = "route_num",
    values_to = "route")|>
  filter (route == "A", ada == TRUE)|>
  select (station_name, line)|>
  distinct()
```

#### Data Set Description 
This data set presents information related to NYC Transit data. More specifically, this CSV file contains information related to entrance and exit for each subway station in New York City. After data cleaning, the following variables were retained: line, station name, station latitude, station longitude, routes taken (1-11), entrance type, entry, vending, and ADA compliance. Other variables in the original data set that were not retained for the purpose of this HW. The raw data is organized in a 1868  x 32 table. The resulting data set has dimensions of 1868 rows x 20 columns.  There are 465 unique stations. Of these, 84 are ADA compliant. The entry variable was also changed to a logical variable. The proportion of station entrances/exits without vending allowed is 0.377. 17 stations serve the A train and are ADA compliant. This data is not tidy because the route number should be single variable in addition to the route. This can be done by transforming the variable from wide to long. 

## Problem 2: Mr.Trash Wheel 
#### Importing Mr. Trash Wheel Data_Excel and data cleaning
```{r}
library(readxl)
MrTrash_df = read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Mr. Trash Wheel", skip = 1, col_names = TRUE) 
MrTrash_df = janitor::clean_names(MrTrash_df) 
```
```{r}
names(MrTrash_df)
```
```{r}
mutate(MrTrash_df, sports_balls = as.integer(round(sports_balls)))
```
#### Add identifier for Mr. Trash Wheel
```{r}
MrTrash_df <- MrTrash_df %>%
  mutate(MrTrash_df = "Mr. Trash Wheel")
```

#### Read and clean Professor Trash Wheel data
```{r}
professor_trash_wheel <- read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Professor Trash Wheel", skip = 1, col_names = TRUE) %>%
select(-contains("notes")) 
```
#### Read and clean Gwynnda data
```{r}
gwynnda_df <- read_excel("/Users/helenyousaf/Desktop/p8105_hw2_hy2912/Trash_Data_New.xlsx", sheet = "Gwynnda Trash Wheel", skip = 1, col_names = TRUE) %>%
  select(-contains("notes")) 
```

#### Combine datasets
```{r}
combined_data <- bind_rows(MrTrash_df, professor_trash_wheel, gwynnda_df)
```

#### Data set description 
This data set includes information for Mr. Trash Wheel  â€œa water-wheel vessel which removes trash from the Inner Harbor in Baltimore, Maryland. The data sheet includes several sheets, but for the purpose of this assignment, only the Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda are utilized. The data was clean by using the janitorr:: clean_names() function to change the column names to lower snake case. In addition, the sports balls data was changed to an integer format. The Mr. Trash Wheel Data has 653 rows of which 121 describe Professor Trash Wheel Data. The important variables included weight, given in tons, and volume (in cubic yards). Other variables include information about trash collected like Polystyrene, Cigarette Butts,Glass Bottles, Plastic Bags, Plastic Bottles, and Sports Balls. 

## Problem 3: The Great British Baking Show 
#### Importing The Great British Baking Show data 
```{r}
viewers_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/viewers.csv")
viewers_df = janitor::clean_names(viewers_df)
names(viewers_df)
```

```{r}
bakers_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/bakers.csv")
bakers_df = janitor::clean_names(bakers_df)
names(bakers_df)
bakers_df = rename(bakers_df, baker = baker_name)
names(bakers_df)
```
```{r}
bakes_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/bakes.csv")
bakes_df = janitor::clean_names(bakes_df)
names(bakes_df)
```
```{r}
results_df = read_csv(file = "/Users/helenyousaf/Desktop/p8105_hw2_hy2912/results.csv" , skip = 2, col_names = TRUE)
results_df = janitor::clean_names(results_df)
names(results_df)
```

#### Clean and tidy bakers dataset
```{r}
bakers_df <- bakers_df %>%
  filter(!is.na(baker))
```

#### Clean and tidy bakes dataset
```{r}
bakes_df <- bakes_df %>%
  filter(!is.na(episode))
```

#### Check for completeness
```{r}
anti_bakers_bakes <- anti_join(bakers_df, bakes_df, by = "baker")
anti_bakes_results <- anti_join(bakes_df, results_df, by = "episode")
anti_results_viewers<- anti_join(results_df, viewers_df, by = "episode")
```

#### Merge datasets
```{r}
final_dataset <- anti_join(bakes_df, bakers_df, results_df, by = "baker")
print(final_dataset)
```

#### Exporting final dataset
```{r}
write_csv(final_dataset, "final_dataset.csv")
```

#### Creating a table for star bakers in Seasons 5 through 10
```{r}
star_bakers_table <- results_df %>%
  filter(series == 5, series == 6, series == 7, series == 8, series == 9, series == 10) %>%
  select(series, episode, baker) %>%
  distinct() 
```

#### Showing the first 10 rows of viewers dataset
```{r}
viewers_clean <- viewers_df %>%
janitor::clean_names()
```

```{r}
head(viewers_clean, 10)
```

#### Calculating average viewership in Season 1 and Season 5
```{r}
library(dplyr)
library(tidyr)
library(knitr)
```

# Create a summary table
```{r}
viewers_df = 
  pivot_longer(
    viewers_df, 
    series_1:series_10,
    names_to = "series", 
    names_prefix = "series_",
    values_to = "viewers")
```

avg_viewership_season_1 <- viewers_df %>%
  summarise(avg_viewership = mean(series1, na.rm = TRUE))


avg_viewership_season_5 <- viewers_df %>%
  summarise(avg_viewership = mean(series_5, na.rm = TRUE))

# Create a summary table
summary_table <- data %>%
  group_by(Season, Episode) %>%
  summarise(Winner = first(Winner)) %>%
  ungroup()

# Display the table

knitr: kable(summary_table, caption = "Star Baker or Winner of Each Episode (Seasons 5-10)")


#### Data set description 
The final data set includes information about the bakes, including the signature and showstopper bakes, of each baker in each series. Rows without relevant information (as represented with NA in the rows) were filtered out. The average viewership in season one was 2.77. The average viewership in season five was 10.04.